## 텐서조작하기

이어서 텐서를 조작하는 방법을 알아보겠습니다

#### 4. 뷰(View)-원소의 수를 유지하면서 텐서의 크기 변경 
파이토치 텐서의 뷰는 넘파이에서의 리쉐이프와 같은 역할을 합니다 
RESHAPE라는 이름에서 알 수 있듯이 텐서의 크기를 변경해주는 역할을 합니다

임의로 다음과 같이 3차원 텐서를 만듭니다

```
t = np.array([[[0, 1, 2],
               [3, 4, 5]],
              [[6, 7, 8],
               [9, 10, 11]]])
ft = torch.FloatTensor(t)
```

ft라는 이름의 3차원 텐서를 만들었습니다 크기를 확인해보겠습니다

```
print(ft.shape)
torch.Size([2, 2, 3])
```

현재 위 텐서의 크기는 (2,2,3)입니다

#### 4-1) 3차원 텐서에서 2차원 텐서로 변경

이제 ft 텐서를 view를 사용하여 크기를 2차원 텐서로 변경해봅시다

```
print(ft.view([-1, 3])) # ft라는 텐서를 (?, 3)의 크기로 변경
print(ft.view([-1, 3]).shape)
tensor([[ 0.,  1.,  2.],
        [ 3.,  4.,  5.],
        [ 6.,  7.,  8.],
        [ 9., 10., 11.]])
torch.Size([4, 3])
```
view([-1,3])이 가지는 의미는 이와 같습니다 -1은 첫번째 차원을 사용자가 잘 모르겠으니 파이토치에 맡기겠다는 의미이고 
3은 두번째 차원의 길이는 3을 가지도록 하라는 의미입니다 다시 말해 현재 3차원 텐서를 2차원 텐서로 변경하되 (?,3)의
크기로 변경하라는 의미입니다  결과적으로 (4,3)의 크기를 가지는 텐서를 얻었습니다

내부적으로 크기 변환은 다음과 같이 이루어졌습니다 (2,2,3) -> (2x2,3)-> (4,3)

규칙을 정리해봅시다
* view는 기본적으로 변경 전과 변경 후의 텐서 안의 원소의 개수가 유지되어야 합니다
* 파이토치의 view는 사이즈가 -1로 설정되면 다른 차원으로부터 해당 값을 유추합니다 

변경 전 텐서의 원소의 수는 (2x2x3)으로 12개였습니다 그리고 변경후 텐서의 원소의 개수 또한 (4x3)으로 12개 였습니다


#### 4-2) 3차원 텐서의 크기 변경

이번에는 3차원 텐서에서 3차원 텐서로 차원은 유지하되, 크기(shape)를 바꾸는 작업을 해보겠습니다. view로 텐서의 크기를 변경하더라도 원소의 수는 유지되어야 한다고 언급한 바 있습니다. 그렇다면 (2 × 2 × 3) 텐서를 (? × 1 × 3) 텐서로 변경하라고 하면 ?는 몇 차원인가요?

(2 × 2 × 3) = (? × 1 × 3) = 12를 만족해야 하므로 ?는 4가 됩니다. 이를 실습으로 확인해봅시다.

```
print(ft.view([-1, 1, 3]))
print(ft.view([-1, 1, 3]).shape)
tensor([[[ 0.,  1.,  2.]],

        [[ 3.,  4.,  5.]],

        [[ 6.,  7.,  8.]],

        [[ 9., 10., 11.]]])
torch.Size([4, 1, 3])
```


#### 5) 스퀴즈(Squeeze) - 1인 차원을 제거한다.
스퀴즈는 차원이 1인 경우에는 해당 차원을 제거합니다.
실습을 위해 임의로 (3 × 1)의 크기를 가지는 2차원 텐서를 만들겠습니다.

```
ft = torch.FloatTensor([[0], [1], [2]])
print(ft)
print(ft.shape)
tensor([[0.],
        [1.],
        [2.]])
torch.Size([3, 1])
```
해당 텐서는 (3 × 1)의 크기를 가집니다. 두번째 차원이 1이므로 squeeze를 사용하면 (3,)의 크기를 가지는 텐서로 변경됩니다.

```
print(ft.squeeze())
print(ft.squeeze().shape)
tensor([0., 1., 2.])
torch.Size([3])
```
위의 결과는 1이었던 두번째 차원이 제거되면서 (3,)의 크기를 가지는 텐서로 변경되어 1차원 벡터가 된 것을 보여줍니다.


#### 6) 언스퀴즈(Unsqueeze) - 특정 위치에 1인 차원을 추가한다

언스퀴즈는 스퀴즈와 정반대입니다 특정 위치에 1인 차원을 추가할 수 있습니다
실습을 위해 임의로 (3,)의 크기를 가지는 1인 차원 텐서를 만들겠습니다 

```
ft = torch.Tensor([0, 1, 2])
print(ft.shape)

torch.Size([3])
```

현재는 차원이 1개인 벡터입니다 여기에 첫번째 차원에 1인 차원을 추가해보겠습니다.
첫번째 차원의 인덱스를 의미하는 숫자 0을 인자로 넣으면 첫번째 차원에서 1인 차원이 추가됩니다

```
print(ft.unsqueeze(0)) # 인덱스가 0부터 시작하므로 0은 첫번째 차원을 의미한다.
print(ft.unsqueeze(0).shape)

tensor([[0., 1., 2.]])
torch.Size([1, 3])
```

위 결과는(3,)의 크기를 가졌던 1차원 벡터가(1,3)의 2차원 텐서로 변경된 것을 보여줍니다 방금한 연산을 앞서 배운 view로도구현이 가능하며 2차원으로 바꾸고 싶으면서 첫번째 차원은 1이기를 원한다면 view에서 (1,-1)을 인자로 사용하면됩니다

```
print(ft.view(1, -1))
print(ft.view(1, -1).shape)

tensor([[0., 1., 2.]])
torch.Size([1, 3])
```

위의 결과는 unsqueeze와 view가 동일한 결과를 만든 것을 보여줍니다. 이번에는 unsqueeze의 인자로 1을 넣어보겠습니다. 
인덱스는 0부터 시작하므로 이는 두번째 차원에 1을 추가하겠다는 것을 의미합니다. 
현재 크기는 (3,)이었으므로 두번째 차원에 1인 차원을 추가하면 (3, 1)의 크기를 가지게 됩니다. 실습을 진행해보겠습니다.

```
print(ft.unsqueeze(1))
print(ft.unsqueeze(1).shape)
tensor([[0.],
        [1.],
        [2.]])
torch.Size([3, 1])
```

이번에는 unsqueeze의 인자로 -1을 넣어보겠습니다. -1은 인덱스 상으로 마지막 차원을 의미합니다. 
현재 크기는 (3,)이었으므로 마지막 차원에 1인 차원을 추가하면 (3, 1)의 크기를 가지게 됩니다. 
다시 말해 현재 텐서의 경우에는 1을 넣은 경우와 -1을 넣은 경우가 결과가 동일합니다. 실습을 진행해보겠습니다.

```
print(ft.unsqueeze(-1))
print(ft.unsqueeze(-1).shape)
tensor([[0.],
        [1.],
        [2.]])
torch.Size([3, 1])
```

맨 뒤에 1인 차원이 추가되면서 1차원 벡터가 (3, 1)의 크기를 가지는 2차원 텐서로 변경되었습니다.

* view(), squeeze(), unsqueeze()는 텐서의 원소 수를 그대로 유지하면서 모양과 차원을 조절합니다.


#### 7) 타입 캐스팅(Type Casting)

텐서에는 자료형이라는 것이 있습니다. 각 데이터형별로 정의되어져 있는데, 예를 들어 32비트의 유동 소수점은 torch.FloatTensor를, 64비트의 부호 있는 정수는 torch.LongTensor를 사용합니다. GPU 연산을 위한 자료형도 있습니다. 예를 들어 torch.cuda.FloatTensor가 그 예입니다.

그리고 **이 자료형을 변환하는 것을 타입 캐스팅이라고 합니다.**

우선 실습을 위해 long 타입의 lt라는 텐서를 선언합니다.

```
lt = torch.LongTensor([1, 2, 3, 4])
print(lt)
```
텐서에다가 .float()를 붙이면 바로 float형으로 타입이 변경됩니다.

```
print(lt.float())
tensor([1., 2., 3., 4.])
```

이번에는 Byte 타입의 bt라는 텐서를 만들어보겠습니다.

```
bt = torch.ByteTensor([True, False, False, True])
print(bt)
tensor([1, 0, 0, 1], dtype=torch.uint8)
```
여기에 .long() 이라고하면 long 타입의 텐서로 변경되고 .float()이라고 하면 float 타입의 텐서로 변경됩니다

```
print(bt.long())
print(bt.float())

tensor([1, 0, 0, 1])
tensor([1., 0., 0., 1.])
```

#### 8) 연결하기 (concatenate)

이번에는 두 텐서를 연결하는 방법에 대해서 알아보겠습니다 우선 (2x2)크기의 텐서를 두 개 만듭니다

```
x = torch.FloatTensor([[1, 2], [3, 4]])
y = torch.FloatTensor([[5, 6], [7, 8]])
```

이제 두 텐서를 torch.cat([])를 통해 연결해보겠습니다 그런데 연결 방법은 한 가지만 잇는 것이 아닙니다
torch.cat은 어느 차원을 늘릴 것인지를 인자로 줄 수 있습니다 예를 들어 dim=0은 첫번째 차원을 늘리라는 의미를 담고있습니다

```
print(torch.cat([x, y], dim=0))
tensor([[1., 2.],
        [3., 4.],
        [5., 6.],
        [7., 8.]])
```

dim=1을 인자로 했더니 두 개의 (2x2) 텐서가 (2x4) 텐서가 된 것을 볼 수 있습니다

* 딥러닝에서는 주로 모델의 입력 또는 중간 연산에서 두개의 텐서를 연결하는 경우가 많습니다 두 텐서를 연결해서 입력으로
* 사용하는 것은 두 가지의 정보를 모두 사용한다는 의미를 가지고 있습니다 


#### 9) 스택킹(Stacking)

연결(concatenate)을 하는 또 다른 방법으로 스택킹(Stacking)이 있습니다 스택킹은 영어로 쌓는다는 의미입니다
때로는 연결을 하는 것보다 스택킹이 더 편리할 때가 있는데, 이는 스택킹이 많은 연산을 포함하고 있기 때문입니다 

실습을 위해 크기가 (2,)로 모두 동일한 3개의 벡터를 만듭니다

```
x = torch.FloatTensor([1, 4])
y = torch.FloatTensor([2, 5])
z = torch.FloatTensor([3, 6])
```

이제 torch.stack을 통해서 3개의 벡터를 모두 스택킹해보겠습니다

```
print(torch.stack([x, y, z]))
tensor([[1., 4.],
        [2., 5.],
        [3., 6.]])
```

위 결과는 3개의 벡터가 순차적으로 쌓여(3x2) 텐서가 된 것을 보여줍니다

![2-3](https://user-images.githubusercontent.com/80239748/116253356-61622400-a7ab-11eb-8089-d5a72f29c51e.JPG)

스택킹은 사실 많은 연산을 한 번에 축약하고 있습니다. 예를 들어 위 작업은 아래의 코드와 동일한 작업입니다

```
print(torch.cat([x.unsqueeze(0), y.unsqueeze(0), z.unsqueeze(0)], dim=0))
```

x,y,z는 기존에는 전부 (2,)의 크기를 가졌습니다. 그런데 .unsqueeze(0)을 하ㅏ므로서 3개의 벡터는 전부 (1,2)의 크기의 차원텐서로 변경됩니다 여기에 연결(concatenate)를 의미하는 cat을 사용하면 (3x2) 텐서가 됩니다

```
tensor([[1., 4.],
        [2., 5.],
        [3., 6.]])
```

위에서는 torch.stack([x,y,z])라는 한 번의 커맨드로 수행했지만, 연결(concatenate)로 이를 구현하려고 했더니 꽤 복잡해졌다
스택킹에 추가적으로 dim을 인자로 줄 수도 있습닌다 이번에는 dim = 1 인자를 주겠습니다 
이는 두번째 차원이 증가하도록 쌓으라는 의미로 해석할 수 있습니다

```
print(torch.stack([x, y, z], dim=1))
tensor([[1., 2., 3.],
        [4., 5., 6.]])
```

위의 결과는 두번째 차원이 증가하도록 스택킹이 된 결과를 보여줍니다 결과적으로 (2x3)텐서가 됩니다

![2-3](https://user-images.githubusercontent.com/80239748/116254794-9d49b900-a7ac-11eb-85a0-06fcff16341f.JPG)





