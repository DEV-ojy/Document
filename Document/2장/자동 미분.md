# 자동 미분 (Autograd)

경사 하강법 코드를 보고있으면 requires_grad = True, backward() 등이 나옵니다. 이는 파이토치에서 제공하고
있는 자동 미분 기능을 수행하고 있다는 것입니다 파이토치의 학습과정을 보다 더 잘 이해하기 위해서 자동 미분에 대해서 이해해봅시다

## 1. 경사 하강법 리뷰

![image](https://user-images.githubusercontent.com/80239748/127140616-d685cf21-ceb8-44b2-a6bc-d0799fe3e30b.png)

경사 하강법을 간단히 복습해보겠습니다 경사 하강법은 비용 함수를 미분하여 이 함수의 기울기(gradient)를 구해서 비용이 최소한 되는
방향을 찾아내는 알고리즘이었습니다 

* 비용 함수를 손실 함수, 오차 함수라고도 부르므로 비용이 최소화 되는 방향이라는 표형 대신 손실이 최소화 되는 방향 또는 최소화 되는
* 방향이라고도 설명할 수 있습니다 

모델이 복잡해질수록 경사 하강법은 넘파이등 직접 코딩하는 것은 까다로운 일입니다 파이토치에서는 이런 수고를 하지 않도록 
자동 미분을 지원합니다 자동미분을 사용하면 미분 계싼을 자동화하여 경사 하강법을 손쉽게 사용할 수 있게 해줍니다


## 2.자동미분 실습하기

```py

import torch 

w = torch.tensor(2.0,requires_grad = True)

y = w**2
z = 2*y + 5

z. backward()

print('수식을 w로 미분한 값 : {}'.format(w.grad))
```
