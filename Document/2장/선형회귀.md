# 선형 회귀(Linear Regression)

이번 챕터에서는 선형회귀 이론에 대해서 이해하고,PyTorch를 이용하여 선형회귀 모델을 만들어보겠습니다

### 1.데이터에 대한 이해

    학습할 데이터에 대해서 알아봅시다

### 2.가설 수립

    가설을 수립하는 방법에 대해서 알아봅시다

### 3.손실 계산하기

    학습 데이터를 이용해서 연속적으로 모델을 개선시키는데 이 때 손실을 이용합니다

### 4.경사 하강법

    학습을 위한 핵심 알고리즘인 경사 하강법에 대해서 이해합니다 

## 1.데이터에 대한 이해(Data Definition)
선형 회귀를 위해 사용할 예제는 공부한 시간과 점수에 대한 상관관계입니다

### 훈련 데이터셋과 테스트 데이터섹

![image](https://user-images.githubusercontent.com/80239748/125445020-85508176-343b-490a-b089-7156688a56f7.png)

어떤 학생이 1시간 공부를 했더니 2점, 다른 학생이 2시간 공부를 했더니 4점, 또 다른 학생이 3시간을 공부했더니 6점을 맞았다. <br>
그렇다면, **내가 4시간을 공부한다면 몇 점을 맞을 숫 있을까요?**

![image](https://user-images.githubusercontent.com/80239748/125445233-1bbd810c-bb81-496f-b669-f5bc14749076.png)

이 질문에 대답하기 위해서 1시간,2시간,3시간을 공부했을 때 각각 2점,4점,6점이 나왔다는 앞서 나온 정보를 이용해야 합니다. <br>
이때 예측을 위해 사용하는 데이터를 **훈련 데이터셋(training dataset)** 이라고 합니다<br>
학습이 끝난 후, 이 모델이 얼마나 잘 작동하는지 판별하는 데이터셋을 **테스터 데이터셋(test dataset)** 이라고 합니다

## 가설(Hypothesis) 수립

머신러닝에서 식을 세울때 이 식을 **가설(Hypothesis)** 이라고 합니다 
**보통 머신러닝에서 가설은 임의로 추축해서 세워보는 식일수도 있고 경험적으로 알고 있는 식일 수 도 있습니다**
그리고 맞는 가설이 아니라고 판단되면 계속 수정해나가게 되는 식이기도 합니다

선형회귀의 가설은 이미 널리 알려져있으므로 고민할 필요가 없습니다 

**선형회귀란** 
```
  학습데이터와 가장 잘 맞는 하나의 직선을 찾는 일입니다 이때 선형회귀의 가설(직선의 방정식)은 이러한 형식을 가집니다
```
<img src="https://user-images.githubusercontent.com/80239748/125446179-fa9b639b-0e19-412c-a4c5-82432e7cab6b.png" width="280" height="100"> 

가설의 **H**를 따서 y대신 쓰기도 하고 

이때 x와 곱해지는 **W를 가중치(Weight)**라고 하며, b는 편향(bias)이라고 합니다  

## 비용함수 (Cost function)에 대한 이해

앞으로 딥 러닝을 학습하면서 인터넷에서 이런 용어들을 본다면, 전부 같은 용어로 생각하시면 됩니다

```
비용함수(cost function) = 손실함수(loss function) = 오차함수(error function) = 목적함수(objective function)
```

비용함수에 대해서 이해하기 위해서 여기서만 잠깐 새로운 예제를 사용해보겠습니다 
어떤 4개의 훈련 데이터가 있고, 이를 2차원 그래프에 4개의 점으로 표혀한 상태이다 

![image](https://user-images.githubusercontent.com/80239748/125593373-b569bff7-06a0-49a7-85ce-21074cda9202.png)

지금 목표는 4개의 점을 가장 잘 표현하는 직선을 그리는 일이다 임의로 3개의 직선을 그려 보겠다 

![image](https://user-images.githubusercontent.com/80239748/125593705-a1d7b65a-c632-4f64-a2b1-71206236f07d.png)


