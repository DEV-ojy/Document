# 원-핫 인코딩(One-Hot Encoding)

주형 데이터를 처리할 때 레이블을 표현하는 방법인 원-핫 인코딩에 대해 알아보겠습니다 

## 원-핫 인코딩이란?

선택해야하는 선택지의 개수만큼의 차원을 가지면서 각 선택지의 인덱스에 해당하는 원소에는 1, 나머지 원소는 0의 값을 
가지도록 하는 표현방법이다 

## 원-핫 벡터의 무작위성

*원-핫 인코딩으로 표현된 벡터를 원-핫 벡터(one-hot vector)라고 한다*

꼭 실제값을 원-핫 벡터로 표현해야만 다중 클래스 분류 문제를 풀 수 있는 것은 아니지만 대부분의 다중 클래스 분류 문제가 
각 클래스 간의 관계가 균등하다는 점에서 원-핫 벡터는 이러한 점을 표현할 수 있는 적절한 표현 방법이다 

다수의 클래스를 분류하는 문제에서는 이진 분류처럼 2개의 숫자 레이블이 아니라 클래스의 개수만큼 숫자 레이블이 필요합니다
이때 직관적으로 생각해볼수 있는 레이블링 방법은 분류해야 할 클래스 전체에 정수 인코딩을 하는 겁니다 
예를 들어 분류해야할 레이블이 {red,green,blue}와 같이 3개라면 각각 0,1,2로 레이블을 할것입니다 또는 분류해야할 클래스가 4개고
인덱스를 숫자 1부터 시작한다고 하면 {baby, child, adolescent, adult}라면 1, 2, 3, 4로 레이블을 해볼수있을것입니다

그런데 일반적인 다중 클래스 분류 문제에서 레이블링 방법으로는 위와 같은 정수 인코딩이 아니라 원-핫인코딩을 사용것이 보다
클래스의 성징르 잘 표현했다고 할 수있습니다 

**그이유를 알아봅시다**

Banana,Tomato,Apple라는 3개의 클래스가 존재한는 문제가 있다고 해봅시다 레이블은 정수 인코딩을 사용하여 각각 1,2,3을부여했습니다
손실 함수로 선형회귀챕터에서 배운 평균 제곱 오차 MSE를 사용하면 정수 인코딩이 어떤 오해를 불러일으킬 수 있는지 확인할수있습니다
아래의 식은 앞서 선형회귀에서 배웠던 MSE를 다시 가져온 것입니다 

![image](https://user-images.githubusercontent.com/80239748/129023008-04819e7b-33a7-41a0-b72f-3038b302fa20.png)

직관적인 오차 크기 비교를 위해 평균을 구하는 수식은 제외하고 제곱 오차로만 판단해봅시다 

실제값이 Tomato일때 예측값이 Banana이었다면 제곱 오차는 다음과 같습니다

![image](https://user-images.githubusercontent.com/80239748/129023343-49bfdb90-756d-43e2-87ef-a8a854150b18.png)

실제값이 Apple일때 예측값이 Banana이었다면 제곱 오차는 다음과 같습니다

![image](https://user-images.githubusercontent.com/80239748/129023380-7a3c97b0-d706-4dda-bc52-ee9fd54e46ae.png)

즉 B와T사이의 오차보다 B와A의 오차가 더 큽니다 이는 기계에서 B가 A보다는 T에 더 가깝다는 정보를 주는 것과 다름없습니다
더많은 클래스에 대해서 정수 인코딩을 수행했다고 해봅시다 

*{Banana :1, Tomato :2, Apple :3, Strawberry :4, ... Watermelon :10}*

이 정수 인코딩은 B가 WM보다는 T에 더 가갑다느 의미를 담고 있습니다 이는 사용자가 부여하고자 했던 정보가 아닙니다
이러한 정수 인코딩의 순서 정보가 도움이 되는 분류 문제도 물론 있습니다 바로 각 클래스가 순서의 의미를 갖고 있어서
회귀를 통해서 분류 문제를 풀 수 있는 경우입니다 예를 들어 {baby, child, adolescent, adult}나 {1층, 2층, 3층, 4층}이나 
{10대, 20대, 30대, 40대}와 같은 경우가 이에 해당됩니다 하지만 일반적인 분류 문제에서는 각 클래스는 순서의 의미를 갖고 있지 않으므로 
각 클래스 간의 오차는 균등한 것이 옳습니다 정수 인코딩과 달리 원-핫 인코딩은 분류 문제 모든 클래스 간의 관계를 균등하게 분배합니다

아래의 세 개의 카테코리에 대해서 원-핫 인코딩을 통해서 레입르을 인코딩 했을때 각 클래스 간의 제곱 오차가 균등함을 보여줍니다

![image](https://user-images.githubusercontent.com/80239748/129024917-3971bd6e-3d54-4c89-9d30-8c5899dbadca.png)

다르게 표현하면 모든 클래스에 대해서 원-핫 인코딩을 통해 얻은 원-핫 벡터들은 모든 쌍에 대해서 유클리드 거리를 구해도
전부 유클리드 거리가 동일합니다 원-핫 벡터는 이처럼 각 클래스의 표현 방법이 무작위성을 가진다는 점을 표현할수있습니다

이러한 원-핫 벡터의 관계의 무작위성은 때로는 단어의 유사성을 구할 수 없다는 단점으로 언급되기도 합니다

